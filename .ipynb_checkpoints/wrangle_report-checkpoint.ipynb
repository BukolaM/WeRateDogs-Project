{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs\n",
    "### A Data Wrangling Report\n",
    "> By Bukola Ajayi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This project was focused on data gathering, wrangling, and visualisation analysis from WeRateDogs Twitter. \n",
    "\n",
    "I thoroughly assessed and cleaned this the entire dataset, this required exceptional effort, so only a subset of its issues (eight quality issues and two tidiness issues at minimum) are reported and communicated.\n",
    "\n",
    "During this project, data was collected from various sources and in a variety of formats.\n",
    "\n",
    "The wrangling process consisted of:\n",
    "\n",
    "#### 1. Data Gathering : The three pieces of data were gathered and represented as pandas dataframes, which included the following steps. \n",
    "• The WeRateDogs Twitter archive (file on hand, manual download of  ' twitter-archive_enhanced.csv '). I downloaded this file programmatically using the Requests library from a provided URL. It included tweets from November, 2015 through August 1, 2017 of basic tweet data (tweet ID, timestamp, text, etc.) that contained columns that were extracted programatically: the rating numerator, rating denominator, dog's name, and dog stages (doggo, floofer, pupper, and puppo).\n",
    "\n",
    "•Image predictions for tweets ('image-predictions.tsv'): This consists of the tweet IDs, image urls, the dog confidence and prediction algorithm.\n",
    "\n",
    "\n",
    "• The Twitter API and Python's Tweepy library were used to save each tweet's entire set of JSON data (with a minimum of tweet ID, retweet count, and favorite count) in a file called \"tweet_json.txt.\"Each tweet's JSON data was written and then read to text file line by line into a Pandas DataFrame only including the desired variables; tweet IDS, retweet count, and favorite count.\n",
    "\n",
    "#### 2. Data Assessing \n",
    "#### 3. Data Cleaning \n",
    "#### 4. Storing, analyzing, and visualizing the wrangled data in order to draw out different insights about the dogs' information. \n",
    "#### 5. Visualising and reporting my data analyses. \n",
    "#### 6. Documenting for data wrangling steps and genarating the insights I discovered throught the entire process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
